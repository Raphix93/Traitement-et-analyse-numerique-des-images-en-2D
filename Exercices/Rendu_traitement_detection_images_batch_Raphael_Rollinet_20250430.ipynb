{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e01997c7",
      "metadata": {
        "id": "e01997c7"
      },
      "source": [
        "# Application de methodes de traitement automatique d'image Ã  un fonds photographique d'archives historique\n",
        "\n",
        "## Du pixel aux images - 32M7138\n",
        "\n",
        "*Printemps 2025 - UniversitÃ© de GenÃ¨ve*\n",
        "\n",
        "*RaphaÃ«l Rollinet (raphael.rollinet@unine.ch)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f70e97b",
      "metadata": {
        "id": "7f70e97b"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ce Markdown effectuÃ© dans le cadre du cours \"Du pixel aux images : introduction au traitement des images 2D\" traite de mÃ©thodes utilisant de l'intelligence artificiel que cela soit avec des modÃ¨les de deep learning ou un LLM multimodale appliquÃ© au traitement de l'image, plus prÃ©cisÃ©ment de la dÃ©tection d'objet sur un fonds d'images anciennes. Mon travail vise Ã  tester diffÃ©rente mÃ©thode et Ã  analyser les rÃ©sultats optenu afin d'en faire la critique du point de vue d'un archiviste.\n",
        "\n",
        "### MÃ©thode de dÃ©tection d'objet\n",
        "\n",
        "La mÃ©thode utilisÃ©e dans le cadre de ce projet sont un mÃ©langes de mÃ©thodes de deep learning pour le traitement d'image. Pour Ãªtre exactes les mÃ©thodes fonctionnent en mode infÃ©rence uniquement, et exploitent des poids figÃ©s issus de lâ€™entraÃ®nement supervisÃ© de grands corpus dâ€™images. Leurs spÃ©cifications sont les suivantes :\n",
        "\n",
        "#### DÃ©tection dâ€™objets par SSD MobileNet v2 (TensorFlow Hub) :\n",
        "Le modÃ¨le utilise une architecture Single Shot MultiBox Detector (SSD) avec un backbone MobileNetV2 optimisÃ© pour les environnements Ã  faibles ressources. SSD gÃ©nÃ¨re un ensemble de boÃ®tes candidates (anchors) Ã  diffÃ©rentes Ã©chelles et positions dans lâ€™image, puis prÃ©dit pour chacune une probabilitÃ© de prÃ©sence dâ€™objet et une rÃ©gression de boÃ®te englobante. Le modÃ¨le a Ã©tÃ© prÃ©alablement entraÃ®nÃ© sur COCO dataset, ce qui permet une dÃ©tection multi-classes directement en infÃ©rence.\n",
        "\n",
        "#### Classification dâ€™image par ViT (Vision Transformer) :\n",
        "Le modÃ¨le ViT Base (patch16-224) repose sur une adaptation des transformeurs Ã  la vision par un dÃ©coupage de lâ€™image en patchs de 16x16, qui sont ensuite linÃ©arisÃ©s et projetÃ©s en embeddings. Ces vecteurs sont enrichis par des encodages positionnels et traitÃ©s par plusieurs couches transformeurs (self-attention). Le modÃ¨le prÃ©dit une seule classe globale pour lâ€™image en sortie du token [CLS]. Il est prÃ©-entraÃ®nÃ© sur ImageNet-21k puis fine-tunÃ© sur ImageNet-1k.\n",
        "\n",
        "### Fonds d'images de la commune de Milvignes\n",
        "\n",
        "Les modÃ¨les de dÃ©tections et classifications des images sera appliquÃ©s Ã  un fonds d'images provenant de l'inventaire des archives de la commune de Milvignes, membre du service intercommunal d'archives de NeuchÃ¢tel, la plateforme de diffusion des inventaires est gÃ©rÃ©e par docuteam SA, entreprise de gestion d'archives qui m'a employÃ© de 2016 Ã  2021. Les images numÃ©risÃ©es par mes soins en format de conservation (TIFF) et archivÃ©es Ã©lectroniquement dans un repository de prÃ©servation numÃ©rique et Ã©galement disponible  disponible en tÃ©lÃ©chargement librement dans un format dÃ©gradÃ© de diffusion (JPEG).\n",
        "\n",
        "![inventaire.png](attachment:inventaire.png)\n",
        "\n",
        "Les images sont disponibles ici : https://milvignes.docuteam.cloud/fr/units/1-archives-communales-de-milvignes-1326-2013/gallery\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f33300",
      "metadata": {
        "id": "06f33300"
      },
      "source": [
        "## ProblÃ©matique\n",
        "\n",
        "Ayant longuement travaillÃ© dans le domaine des archives, la thÃ©matique d'appliquer les mÃ©thodes vues dans le cadre de ce cours sur un fonds d'archives est un sujet intÃ©ressant dans son potentiel d'application sur un fonds d'archives d'images. Dans les institutions patrimoniales, les images sont un support courant, ma problÃ©matique sera donc appliquÃ©e Ã  un fonds ancien d'images numÃ©risÃ©es de la commune de Milvignes (NE). Mon questionnement porte sur l'application de cette mÃ©thode utilisant des modÃ¨les de deep learning entrainÃ© sur des images relativement rÃ©centes, mais ici appliquÃ© Ã  un fonds d'images anciennes (~1900).\n",
        "\n",
        "### Question de recherche\n",
        "\n",
        "- \"Quel est le potentiel de la dÃ©tection d'objet dans le traitement, particuliÃ¨rement pour la description de fonds d'images en archives ?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8ec479",
      "metadata": {
        "id": "3a8ec479"
      },
      "source": [
        "## MÃ©thodologie\n",
        "\n",
        "Le code utilisÃ© est adaptÃ© du code vu en cours, il vise Ã  effectuer une dÃ©tection d'objet sur des images, tout en rÃ©pondant Ã  des contraintes mÃ©tiers qui sont par exemple un besoin d'automatiser le traitement Ã  partir d'un workflow. Mais Ã©galement en termes de rendu, un archiviste aura besoin d'extraire les dÃ©tections sous format CSV afin qu'elles soient intÃ©grÃ©es aux notices d'un systÃ¨me d'information archivistique par exemple sous la forme d'une indexation. Le code permet Ã  n'importe quel archiviste avec des notions informatiques minimales de l'exÃ©cuter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2e799e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2e799e",
        "outputId": "69821356-8cad-4afe-8c59-8c1131dabc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Monter Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f26d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69f26d37",
        "outputId": "59034acd-3bff-4fca-f68d-70fbe5f5d496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Collecting tensorflow_hub\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (5.29.4)\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow<2.20,>=2.19 (from tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n",
            "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow, tf-keras, tensorflow_hub\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_hub-0.16.1 tf-keras-2.19.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "#Installation des librairies (si nÃ©cessaire)\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow_hub\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87439cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a87439cc",
        "outputId": "17e0c6e6-4fbb-41a3-d5fb-b159e0d8ce08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Importation des librairies Python\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e604ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "061868647da24502b749a2c8f0117e9e",
            "143d933ad86e4a49ac8f3c7e19156610",
            "1c724a5d2bdc4c32b5a12569f12ea10b",
            "760c4a79c103485a83ff55592263eea4",
            "843875d686f949b883aed003d9ed1776",
            "1743e33f58a14b638885a8e0666789e8",
            "c4ec3b7b366a4c7694d26bda0a1a96d7",
            "80ce636d8f0740a786aceceff0f11dfb",
            "e52d431de7e740089fb4f9fd09cda849",
            "d95161adb08b4e9cb3a7a6e7bdb873a7",
            "5122046fc5414ed4bbf1e2cc0e6776be",
            "7c667bf5b2fb4fb6a836d7823db27293",
            "504a6c6ee1724014842e4be4e90a7775",
            "18aa83fb3f60474da01d46a71c498032",
            "9b30859b93784692b2c40fbfa8f47792",
            "149f8555ca534e249373c7f8ad8c1b3f",
            "f86ffd40cdca4667ab1c8c79ea05bb8f",
            "316ce7b4a3374e718526d57d3ba35d8d",
            "e1d4e40588bd416a84065273203cbdbf",
            "2a35b312001d450a8029951ef8bb37fc",
            "e600e4083c4b4a7c8856a2ad0378168b",
            "f1270dc1e9414ce3a7a50232fe39811f",
            "4afd3b1e942544928edeb4c768d625ca",
            "3c151624b524489a9df115165f8f14a4",
            "9bf3cc31904c429a99ef0ef63daf3f2a",
            "782500ce9b52473db6ea10458df833a0",
            "6dfe57b9a3da444eb08cc5a3b36e1098",
            "082d957918ec41fc91d3455e60d47bd4",
            "d01eb196e9fe46c3ac78b9b441b3d654",
            "7b8f3008d6e44d6ab8626ed175e5276e",
            "73f8e849c337471690e6d415bdf3bf2a",
            "9cdf008d9325439199e574259b9487a5",
            "d78ec22c3df04e04b337e777d8ef8da9"
          ]
        },
        "id": "08e604ac",
        "outputId": "b016b891-ca19-4f82-97c3-33caadc1d0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "061868647da24502b749a2c8f0117e9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c667bf5b2fb4fb6a836d7823db27293"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4afd3b1e942544928edeb4c768d625ca"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Charger les modÃ¨les (dÃ©tection + classification)\n",
        "\n",
        "# ModÃ¨le de dÃ©tection SSD MobileNet V2\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\")\n",
        "\n",
        "# ModÃ¨le ViT pour classification d'image\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee26f213",
      "metadata": {
        "id": "ee26f213"
      },
      "outputs": [],
      "source": [
        "# Liste des noms de classes (80 classes COCO)\n",
        "classe = np.array([\n",
        "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
        "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "    'hair drier', 'toothbrush'\n",
        "])\n",
        "classes = np.concatenate([classe, np.repeat('none', 100)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f91afd",
      "metadata": {
        "id": "f5f91afd"
      },
      "outputs": [],
      "source": [
        "#  Ã€ adapter : Mettre le dossier Images dans Google Drive\n",
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/images\"  # Adapter le chemin selon l'utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc20cc3",
      "metadata": {
        "id": "8dc20cc3"
      },
      "outputs": [],
      "source": [
        "# Liste pour stocker les rÃ©sultats\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645d54fa",
      "metadata": {
        "id": "645d54fa"
      },
      "outputs": [],
      "source": [
        "# CrÃ©ation d'une fonction de detection et classification pour le traitement de l'image\n",
        "## Traite une image avec SSD MobileNet (dÃ©tection) et ViT (classification).\n",
        "## Sauvegarde l'image annotÃ©e et stocke les rÃ©sultats dans la liste globale 'results'.\n",
        "\n",
        "def process_image_with_detection_and_classification(image_path):\n",
        "\n",
        "    # Lire l'image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Erreur : impossible de lire {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Convertir en RGB pour affichage et modÃ¨les\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = tf.convert_to_tensor(image_rgb)[tf.newaxis, ...]\n",
        "\n",
        "    # DÃ©tection d'objets\n",
        "    detections = detector(input_tensor)\n",
        "    boxes = detections['detection_boxes'][0].numpy()\n",
        "    scores = detections['detection_scores'][0].numpy()\n",
        "    detected_classes = detections['detection_classes'][0].numpy().astype(np.uint8)\n",
        "\n",
        "    # PrÃ©parer les annotations et objets dÃ©tectÃ©s\n",
        "    object_labels = []\n",
        "    height, width, _ = image.shape\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] < 0.3:\n",
        "            continue\n",
        "        label = classes[detected_classes[i]]\n",
        "        object_labels.append(label)\n",
        "\n",
        "        # BoÃ®te englobante\n",
        "        box = boxes[i] * np.array([height, width, height, width])\n",
        "        box = box.astype(np.int32)\n",
        "        cv2.rectangle(image_rgb, (box[1], box[0]), (box[3], box[2]), (0, 255, 0), 2)\n",
        "        cv2.putText(image_rgb, label, (box[1], box[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Classification avec ViT\n",
        "    pil_image = Image.fromarray(image_rgb)\n",
        "    inputs = processor(images=pil_image, return_tensors=\"pt\")\n",
        "    outputs = vit_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "    predicted_label = vit_model.config.id2label[predicted_class_idx]\n",
        "\n",
        "    # Sauvegarde de lâ€™image annotÃ©e dans /Resultat/annotated\n",
        "    result_folder = os.path.join(folder_path, \"Resultat\")\n",
        "    annotated_folder = os.path.join(result_folder, \"annotated\")\n",
        "    os.makedirs(annotated_folder, exist_ok=True)\n",
        "\n",
        "    save_path = os.path.join(annotated_folder, os.path.basename(image_path))\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # Affichage pour visualisation\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"{os.path.basename(image_path)}\\nâ†’ ViT : {predicted_label}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Stockage des rÃ©sultats pour export CSV\n",
        "    results.append({\n",
        "        \"image\": os.path.basename(image_path),\n",
        "        \"detected_objects\": \", \".join(object_labels),\n",
        "        \"vit_prediction\": predicted_label\n",
        "    })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b67aa6",
      "metadata": {
        "id": "18b67aa6"
      },
      "outputs": [],
      "source": [
        "# Appliquer Ã  toutes les images prÃ©sentes dans le dossiers \"images\"\n",
        "supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(supported_formats)]\n",
        "\n",
        "print(f\"{len(image_files)} images trouvÃ©es.\")\n",
        "\n",
        "for image_path in image_files:\n",
        "    process_image_with_detection_and_classification(image_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def87294",
      "metadata": {
        "id": "def87294"
      },
      "outputs": [],
      "source": [
        "# CrÃ©er un sous-dossier \"RÃ©sultat\" dans le dossier Drive d'origine\n",
        "result_folder = os.path.join(folder_path, \"Resultat\")\n",
        "os.makedirs(result_folder, exist_ok=True)\n",
        "\n",
        "# DÃ©finir le chemin de sortie du CSV dans ce dossier\n",
        "csv_output_path = os.path.join(result_folder, \"resultats_detection_classification.csv\")\n",
        "\n",
        "# Export du DataFrame en CSV\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(csv_output_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"CSV enregistrÃ© ici : {csv_output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1386b7",
      "metadata": {
        "id": "0a1386b7"
      },
      "source": [
        "## RÃ©sultat\n",
        "\n",
        "Les rÃ©sultats appliquÃ©s Ã  un fonds d'images anciennes sont mitigÃ©s. Le code a parfaitement fonctionnÃ© et le traitement de dÃ©tection et classification a parfaitement Ã©tÃ© appliquÃ© sur le fonds d'images. Cependant les images utilisÃ©es mettent en Ã©vidence certaines limitations de cette mÃ©thode.\n",
        "\n",
        "La premiÃ¨re provient probablement des images elles-mÃªmes, il s'agit de JPEG utilisÃ© pour la diffusion sur le web avec une faible rÃ©solution. Les modÃ¨les se basant sur les pixels de l'image pour dÃ©tecter les objets, cela influence le rÃ©sultat final.\n",
        "\n",
        "DeuxiÃ¨mement les modÃ¨les utilisÃ©s ont Ã©tÃ© entrainÃ©s sur des images rÃ©centes, cela peut-Ãªtre observÃ© notamment avec les classes \"COCO\". Le modÃ¨le fonctionnant par infÃ©rence peu importe l'image, il y a un taux d'erreur plus important sur des images anciennes. Cela peut Ãªtre partiellement paliÃ© en enlevant des classes. Neanmoins cela rÃ©ste un biais inhÃ©rant Ã  ces modÃ¨les."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986b89be",
      "metadata": {
        "id": "986b89be"
      },
      "source": [
        "# Traitement par LLM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Ã‰tape 1 : Installer et importer les bibliothÃ¨ques nÃ©cessaires --\n",
        "!pip install openai pillow --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu9x0Z8Og4XJ",
        "outputId": "c90d4778-fe0b-4cac-bd88-375398a3035f"
      },
      "id": "Xu9x0Z8Og4XJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/661.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m481.3/661.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m661.3/661.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/351.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m351.8/351.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "from PIL import Image, UnidentifiedImageError"
      ],
      "metadata": {
        "id": "4d4sTJRskXkk"
      },
      "id": "4d4sTJRskXkk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 2 : Configuration OpenRouter ---\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=\"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\"  # Remplace par ta clÃ© OpenRouter\n",
        ")"
      ],
      "metadata": {
        "id": "o41VrrNVkbWK"
      },
      "id": "o41VrrNVkbWK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 3 : Fonctions utilitaires ---\n",
        "def encode_image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def is_image_valid(image_path):\n",
        "    try:\n",
        "        Image.open(image_path).verify()\n",
        "        return True\n",
        "    except (UnidentifiedImageError, IOError):\n",
        "        return False\n",
        "\n",
        "def query_llama_vision(image_path):\n",
        "    base64_image = encode_image_to_base64(image_path)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-3.2-11b-vision-instruct:free\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Provide a short descriptive caption for this archival photograph in English, focusing on historical or visual context.\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def query_llama_vision_with_retry(image_path, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            if not is_image_valid(image_path):\n",
        "                return \"[ERROR] Unreadable or corrupted image\"\n",
        "            return query_llama_vision(image_path)\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                print(f\"âš ï¸ Attempt {attempt+1} failed: {e}. Retrying in {delay} sec...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                return f\"[ERROR] {str(e)}\""
      ],
      "metadata": {
        "id": "DmSxQXcekm61"
      },
      "id": "DmSxQXcekm61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 4 : ParamÃ¨tres de chemin ---\n",
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/images\"\n",
        "result_folder = \"/content/drive/MyDrive/Colab_Notebooks/images/Resultat\"\n",
        "os.makedirs(result_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "E-De9z82kuM1"
      },
      "id": "E-De9z82kuM1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 5 : Liste des fichiers image ---\n",
        "image_filenames = sorted([\n",
        "    f for f in os.listdir(folder_path)\n",
        "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "])"
      ],
      "metadata": {
        "id": "p-RcjZKkk3Vm"
      },
      "id": "p-RcjZKkk3Vm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 6 : GÃ©nÃ©ration des descriptions avec rendu ---\n",
        "results_llm = []\n",
        "for filename in tqdm(image_filenames, desc=\"ğŸ” Interrogation de LLaMA 3 Vision\"):\n",
        "    image_path = os.path.join(folder_path, filename)\n",
        "    llm_description = query_llama_vision_with_retry(image_path)\n",
        "    results_llm.append({\n",
        "        \"filename\": filename,\n",
        "        \"llm_description\": llm_description\n",
        "    })\n",
        "    time.sleep(2)  # Respect des limites d'OpenRouter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMYyn5DQlB8g",
        "outputId": "f336d52f-5dd5-4d68-ef1b-fe63f5b48177"
      },
      "id": "jMYyn5DQlB8g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Interrogation de LLaMA 3 Vision:   6%|â–Œ         | 1/18 [00:05<01:29,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  11%|â–ˆ         | 2/18 [00:12<01:44,  6.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  17%|â–ˆâ–‹        | 3/18 [00:20<01:49,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  22%|â–ˆâ–ˆâ–       | 4/18 [00:28<01:45,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Interrogation de LLaMA 3 Vision:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:52<01:20,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [01:00<01:16,  7.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Interrogation de LLaMA 3 Vision:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [01:13<00:55,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [01:20<00:49,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rğŸ” Interrogation de LLaMA 3 Vision:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [01:27<00:42,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Interrogation de LLaMA 3 Vision:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [01:40<00:26,  6.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Interrogation de LLaMA 3 Vision: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [02:03<00:00,  6.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Ã‰tape 7 : Sauvegarde dans un CSV ---\n",
        "csv_output_path = os.path.join(result_folder, \"rÃ©sultats_llm_llama32.csv\")\n",
        "pd.DataFrame(results_llm).to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
        "print(f\"âœ… RÃ©sultats enregistrÃ©s dans : {csv_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_KGm10jlDs2",
        "outputId": "66db86e8-c5ce-454d-c3b6-dbade5b7ca9e"
      },
      "id": "L_KGm10jlDs2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RÃ©sultats enregistrÃ©s dans : /content/drive/MyDrive/Colab_Notebooks/images/Resultat/rÃ©sultats_llm_llama32.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "484c9d53",
      "metadata": {
        "id": "484c9d53"
      },
      "source": [
        "## Mise en perspectives et conclusion\n",
        "\n",
        "En conclusion, le fonctionnement du code permettant un traitment par lot, rend la mÃ©thode intÃ©ressante sur des fonds d'images en archives. De plus le rendu en CSV permet des imports, permettant d'utiliser ces classifications comme methode d'indexation automatique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d753c2c6",
      "metadata": {
        "id": "d753c2c6"
      },
      "source": [
        "## Bibliographie"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "061868647da24502b749a2c8f0117e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_143d933ad86e4a49ac8f3c7e19156610",
              "IPY_MODEL_1c724a5d2bdc4c32b5a12569f12ea10b",
              "IPY_MODEL_760c4a79c103485a83ff55592263eea4"
            ],
            "layout": "IPY_MODEL_843875d686f949b883aed003d9ed1776"
          }
        },
        "143d933ad86e4a49ac8f3c7e19156610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1743e33f58a14b638885a8e0666789e8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4ec3b7b366a4c7694d26bda0a1a96d7",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "1c724a5d2bdc4c32b5a12569f12ea10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ce636d8f0740a786aceceff0f11dfb",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e52d431de7e740089fb4f9fd09cda849",
            "value": 160
          }
        },
        "760c4a79c103485a83ff55592263eea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95161adb08b4e9cb3a7a6e7bdb873a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5122046fc5414ed4bbf1e2cc0e6776be",
            "value": "â€‡160/160â€‡[00:00&lt;00:00,â€‡22.6kB/s]"
          }
        },
        "843875d686f949b883aed003d9ed1776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1743e33f58a14b638885a8e0666789e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ec3b7b366a4c7694d26bda0a1a96d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ce636d8f0740a786aceceff0f11dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52d431de7e740089fb4f9fd09cda849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d95161adb08b4e9cb3a7a6e7bdb873a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5122046fc5414ed4bbf1e2cc0e6776be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c667bf5b2fb4fb6a836d7823db27293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504a6c6ee1724014842e4be4e90a7775",
              "IPY_MODEL_18aa83fb3f60474da01d46a71c498032",
              "IPY_MODEL_9b30859b93784692b2c40fbfa8f47792"
            ],
            "layout": "IPY_MODEL_149f8555ca534e249373c7f8ad8c1b3f"
          }
        },
        "504a6c6ee1724014842e4be4e90a7775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86ffd40cdca4667ab1c8c79ea05bb8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_316ce7b4a3374e718526d57d3ba35d8d",
            "value": "config.json:â€‡100%"
          }
        },
        "18aa83fb3f60474da01d46a71c498032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d4e40588bd416a84065273203cbdbf",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a35b312001d450a8029951ef8bb37fc",
            "value": 69665
          }
        },
        "9b30859b93784692b2c40fbfa8f47792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e600e4083c4b4a7c8856a2ad0378168b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f1270dc1e9414ce3a7a50232fe39811f",
            "value": "â€‡69.7k/69.7kâ€‡[00:00&lt;00:00,â€‡3.49MB/s]"
          }
        },
        "149f8555ca534e249373c7f8ad8c1b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86ffd40cdca4667ab1c8c79ea05bb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316ce7b4a3374e718526d57d3ba35d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1d4e40588bd416a84065273203cbdbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a35b312001d450a8029951ef8bb37fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e600e4083c4b4a7c8856a2ad0378168b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1270dc1e9414ce3a7a50232fe39811f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afd3b1e942544928edeb4c768d625ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c151624b524489a9df115165f8f14a4",
              "IPY_MODEL_9bf3cc31904c429a99ef0ef63daf3f2a",
              "IPY_MODEL_782500ce9b52473db6ea10458df833a0"
            ],
            "layout": "IPY_MODEL_6dfe57b9a3da444eb08cc5a3b36e1098"
          }
        },
        "3c151624b524489a9df115165f8f14a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082d957918ec41fc91d3455e60d47bd4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d01eb196e9fe46c3ac78b9b441b3d654",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "9bf3cc31904c429a99ef0ef63daf3f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8f3008d6e44d6ab8626ed175e5276e",
            "max": 346293852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73f8e849c337471690e6d415bdf3bf2a",
            "value": 346293852
          }
        },
        "782500ce9b52473db6ea10458df833a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cdf008d9325439199e574259b9487a5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d78ec22c3df04e04b337e777d8ef8da9",
            "value": "â€‡346M/346Mâ€‡[00:01&lt;00:00,â€‡296MB/s]"
          }
        },
        "6dfe57b9a3da444eb08cc5a3b36e1098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082d957918ec41fc91d3455e60d47bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d01eb196e9fe46c3ac78b9b441b3d654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8f3008d6e44d6ab8626ed175e5276e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f8e849c337471690e6d415bdf3bf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cdf008d9325439199e574259b9487a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78ec22c3df04e04b337e777d8ef8da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}