{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e01997c7",
      "metadata": {
        "id": "e01997c7"
      },
      "source": [
        "# Application de methodes de traitement automatique d'image à un fonds photographique d'archives historique\n",
        "\n",
        "## Du pixel aux images - 32M7138\n",
        "\n",
        "*Printemps 2025 - Université de Genève*\n",
        "\n",
        "*Raphaël Rollinet (raphael.rollinet@unine.ch)*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f70e97b",
      "metadata": {
        "id": "7f70e97b"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ce Markdown effectué dans le cadre du cours \"Du pixel aux images : introduction au traitement des images 2D\" traite de méthodes utilisant de l'intelligence artificiel que cela soit avec des modèles de deep learning ou un LLM multimodale appliqué au traitement de l'image, plus précisément de la détection d'objet sur un fonds d'images anciennes. Mon travail vise à tester différente méthode et à analyser les résultats optenu afin d'en faire la critique du point de vue d'un archiviste.\n",
        "\n",
        "### Fonds d'images de la commune de Milvignes\n",
        "\n",
        "Les modèles de détections et classifications des images sera appliqués à un fonds d'images provenant de l'inventaire des archives de la commune de Milvignes, membre du service intercommunal d'archives de Neuchâtel, la plateforme de diffusion des inventaires est gérée par docuteam SA, entreprise de gestion d'archives qui m'a employé de 2016 à 2021. Les images numérisées par mes soins en format de conservation (TIFF) et archivées électroniquement dans un repository de préservation numérique et également disponible  disponible en téléchargement librement dans un format dégradé de diffusion (JPEG).\n",
        "\n",
        "![inventaire.png](attachment:inventaire.png)\n",
        "\n",
        "Les images sont disponibles ici : https://milvignes.docuteam.cloud/fr/units/1-archives-communales-de-milvignes-1326-2013/gallery\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f33300",
      "metadata": {
        "id": "06f33300"
      },
      "source": [
        "## Problématique\n",
        "\n",
        "Ayant longuement travaillé dans le domaine des archives, la thématique d'appliquer les méthodes vues dans le cadre de ce cours sur un fonds d'archives est un sujet intéressant dans son potentiel d'application sur un fonds d'archives d'images. Dans les institutions patrimoniales, les images sont un support courant, ma problématique sera donc appliquée à un fonds ancien d'images numérisées de la commune de Milvignes (NE). Mon questionnement porte sur l'application de cette méthode utilisant des modèles de deep learning entrainé sur des images relativement récentes, mais ici appliqué à un fonds d'images anciennes (~1900).\n",
        "\n",
        "### Question de recherche\n",
        "\n",
        "- \"Quel est le potentiel de la détection d'objet dans le traitement, particulièrement pour la description de fonds d'images en archives ?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8ec479",
      "metadata": {
        "id": "3a8ec479"
      },
      "source": [
        "## Méthodologie\n",
        "\n",
        "Le code utilisé est adapté du code vu en cours, il vise à effectuer une détection d'objet sur des images, tout en répondant à des contraintes métiers qui sont par exemple un besoin d'automatiser le traitement à partir d'un workflow. Mais également en termes de rendu, un archiviste aura besoin d'extraire les détections sous format CSV afin qu'elles soient intégrées aux notices d'un système d'information archivistique par exemple sous la forme d'une indexation. Le code permet à n'importe quel archiviste avec des notions informatiques minimales de l'exécuter.\n",
        "\n",
        "### Méthode de détection d'objet\n",
        "\n",
        "La méthode utilisée dans le cadre de ce projet sont un mélanges de méthodes de deep learning pour le traitement d'image. Pour être exactes les méthodes fonctionnent en mode inférence uniquement, et exploitent des poids figés issus de l’entraînement supervisé de grands corpus d’images. Leurs spécifications sont les suivantes :\n",
        "\n",
        "#### Détection d’objets par SSD MobileNet v2 (TensorFlow Hub) :\n",
        "Le modèle utilise une architecture Single Shot MultiBox Detector (SSD) avec un backbone MobileNetV2 optimisé pour les environnements à faibles ressources. SSD génère un ensemble de boîtes candidates (anchors) à différentes échelles et positions dans l’image, puis prédit pour chacune une probabilité de présence d’objet et une régression de boîte englobante. Le modèle a été préalablement entraîné sur COCO dataset, ce qui permet une détection multi-classes directement en inférence.\n",
        "\n",
        "#### Classification d’image par ViT (Vision Transformer) :\n",
        "Le modèle ViT Base (patch16-224) repose sur une adaptation des transformeurs à la vision par un découpage de l’image en patchs de 16x16, qui sont ensuite linéarisés et projetés en embeddings. Ces vecteurs sont enrichis par des encodages positionnels et traités par plusieurs couches transformeurs (self-attention). Le modèle prédit une seule classe globale pour l’image en sortie du token [CLS]. Il est pré-entraîné sur ImageNet-21k puis fine-tuné sur ImageNet-1k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d2e799e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2e799e",
        "outputId": "ee88e435-1c71-4a2b-f1b8-447ac2ca68c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Monter Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f26d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69f26d37",
        "outputId": "59034acd-3bff-4fca-f68d-70fbe5f5d496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.11.0.86\n",
            "Collecting tensorflow_hub\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow_hub) (5.29.4)\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow<2.20,>=2.19 (from tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.4.0)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (1.71.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.5.1)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.3.6)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n",
            "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow, tf-keras, tensorflow_hub\n",
            "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_hub-0.16.1 tf-keras-2.19.0 werkzeug-3.1.3 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "#Installation des librairies (si nécessaire)\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow_hub\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a87439cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a87439cc",
        "outputId": "17e0c6e6-4fbb-41a3-d5fb-b159e0d8ce08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Importation des librairies Python\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e604ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "061868647da24502b749a2c8f0117e9e",
            "143d933ad86e4a49ac8f3c7e19156610",
            "1c724a5d2bdc4c32b5a12569f12ea10b",
            "760c4a79c103485a83ff55592263eea4",
            "843875d686f949b883aed003d9ed1776",
            "1743e33f58a14b638885a8e0666789e8",
            "c4ec3b7b366a4c7694d26bda0a1a96d7",
            "80ce636d8f0740a786aceceff0f11dfb",
            "e52d431de7e740089fb4f9fd09cda849",
            "d95161adb08b4e9cb3a7a6e7bdb873a7",
            "5122046fc5414ed4bbf1e2cc0e6776be",
            "7c667bf5b2fb4fb6a836d7823db27293",
            "504a6c6ee1724014842e4be4e90a7775",
            "18aa83fb3f60474da01d46a71c498032",
            "9b30859b93784692b2c40fbfa8f47792",
            "149f8555ca534e249373c7f8ad8c1b3f",
            "f86ffd40cdca4667ab1c8c79ea05bb8f",
            "316ce7b4a3374e718526d57d3ba35d8d",
            "e1d4e40588bd416a84065273203cbdbf",
            "2a35b312001d450a8029951ef8bb37fc",
            "e600e4083c4b4a7c8856a2ad0378168b",
            "f1270dc1e9414ce3a7a50232fe39811f",
            "4afd3b1e942544928edeb4c768d625ca",
            "3c151624b524489a9df115165f8f14a4",
            "9bf3cc31904c429a99ef0ef63daf3f2a",
            "782500ce9b52473db6ea10458df833a0",
            "6dfe57b9a3da444eb08cc5a3b36e1098",
            "082d957918ec41fc91d3455e60d47bd4",
            "d01eb196e9fe46c3ac78b9b441b3d654",
            "7b8f3008d6e44d6ab8626ed175e5276e",
            "73f8e849c337471690e6d415bdf3bf2a",
            "9cdf008d9325439199e574259b9487a5",
            "d78ec22c3df04e04b337e777d8ef8da9"
          ]
        },
        "id": "08e604ac",
        "outputId": "b016b891-ca19-4f82-97c3-33caadc1d0aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "061868647da24502b749a2c8f0117e9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c667bf5b2fb4fb6a836d7823db27293",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4afd3b1e942544928edeb4c768d625ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Charger les modèles (détection + classification)\n",
        "\n",
        "# Modèle de détection SSD MobileNet V2\n",
        "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1\")\n",
        "\n",
        "# Modèle ViT pour classification d'image\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee26f213",
      "metadata": {
        "id": "ee26f213"
      },
      "outputs": [],
      "source": [
        "# Liste des noms de classes (80 classes COCO)\n",
        "classe = np.array([\n",
        "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
        "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "    'hair drier', 'toothbrush'\n",
        "])\n",
        "classes = np.concatenate([classe, np.repeat('none', 100)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f91afd",
      "metadata": {
        "id": "f5f91afd"
      },
      "outputs": [],
      "source": [
        "#  À adapter : Mettre le dossier Images dans Google Drive\n",
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/images\"  # Adapter le chemin selon l'utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc20cc3",
      "metadata": {
        "id": "8dc20cc3"
      },
      "outputs": [],
      "source": [
        "# Liste pour stocker les résultats\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "645d54fa",
      "metadata": {
        "id": "645d54fa"
      },
      "outputs": [],
      "source": [
        "# Création d'une fonction de detection et classification pour le traitement de l'image\n",
        "## Traite une image avec SSD MobileNet (détection) et ViT (classification).\n",
        "## Sauvegarde l'image annotée et stocke les résultats dans la liste globale 'results'.\n",
        "\n",
        "def process_image_with_detection_and_classification(image_path):\n",
        "\n",
        "    # Lire l'image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Erreur : impossible de lire {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Convertir en RGB pour affichage et modèles\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = tf.convert_to_tensor(image_rgb)[tf.newaxis, ...]\n",
        "\n",
        "    # Détection d'objets\n",
        "    detections = detector(input_tensor)\n",
        "    boxes = detections['detection_boxes'][0].numpy()\n",
        "    scores = detections['detection_scores'][0].numpy()\n",
        "    detected_classes = detections['detection_classes'][0].numpy().astype(np.uint8)\n",
        "\n",
        "    # Préparer les annotations et objets détectés\n",
        "    object_labels = []\n",
        "    height, width, _ = image.shape\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] < 0.3:\n",
        "            continue\n",
        "        label = classes[detected_classes[i]]\n",
        "        object_labels.append(label)\n",
        "\n",
        "        # Boîte englobante\n",
        "        box = boxes[i] * np.array([height, width, height, width])\n",
        "        box = box.astype(np.int32)\n",
        "        cv2.rectangle(image_rgb, (box[1], box[0]), (box[3], box[2]), (0, 255, 0), 2)\n",
        "        cv2.putText(image_rgb, label, (box[1], box[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Classification avec ViT\n",
        "    pil_image = Image.fromarray(image_rgb)\n",
        "    inputs = processor(images=pil_image, return_tensors=\"pt\")\n",
        "    outputs = vit_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class_idx = logits.argmax(-1).item()\n",
        "    predicted_label = vit_model.config.id2label[predicted_class_idx]\n",
        "\n",
        "    # Sauvegarde de l’image annotée dans /Resultat/annotated\n",
        "    result_folder = os.path.join(folder_path, \"Resultat\")\n",
        "    annotated_folder = os.path.join(result_folder, \"annotated\")\n",
        "    os.makedirs(annotated_folder, exist_ok=True)\n",
        "\n",
        "    save_path = os.path.join(annotated_folder, os.path.basename(image_path))\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # Affichage pour visualisation\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"{os.path.basename(image_path)}\\n→ ViT : {predicted_label}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Stockage des résultats pour export CSV\n",
        "    results.append({\n",
        "        \"image\": os.path.basename(image_path),\n",
        "        \"detected_objects\": \", \".join(object_labels),\n",
        "        \"vit_prediction\": predicted_label\n",
        "    })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b67aa6",
      "metadata": {
        "id": "18b67aa6"
      },
      "outputs": [],
      "source": [
        "# Appliquer à toutes les images présentes dans le dossiers \"images\"\n",
        "supported_formats = ('.jpg', '.jpeg', '.png', '.bmp')\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith(supported_formats)]\n",
        "\n",
        "print(f\"{len(image_files)} images trouvées.\")\n",
        "\n",
        "for image_path in image_files:\n",
        "    process_image_with_detection_and_classification(image_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def87294",
      "metadata": {
        "id": "def87294"
      },
      "outputs": [],
      "source": [
        "# Créer un sous-dossier \"Résultat\" dans le dossier Drive d'origine\n",
        "result_folder = os.path.join(folder_path, \"Resultat\")\n",
        "os.makedirs(result_folder, exist_ok=True)\n",
        "\n",
        "# Définir le chemin de sortie du CSV dans ce dossier\n",
        "csv_output_path = os.path.join(result_folder, \"resultats_detection_classification.csv\")\n",
        "\n",
        "# Export du DataFrame en CSV\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(csv_output_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"CSV enregistré ici : {csv_output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1386b7",
      "metadata": {
        "id": "0a1386b7"
      },
      "source": [
        "## Résultat\n",
        "\n",
        "Les résultats appliqués à un fonds d'images anciennes sont mitigés. Le code a parfaitement fonctionné et le traitement de détection et classification a parfaitement été appliqué sur le fonds d'images. Cependant les images utilisées mettent en évidence certaines limitations de cette méthode.\n",
        "\n",
        "La première provient probablement des images elles-mêmes, il s'agit de JPEG utilisé pour la diffusion sur le web avec une faible résolution. Les modèles se basant sur les pixels de l'image pour détecter les objets, cela influence le résultat final.\n",
        "\n",
        "Deuxièmement les modèles utilisés ont été entrainés sur des images récentes, cela peut-être observé notamment avec les classes \"COCO\". Le modèle fonctionnant par inférence peu importe l'image, il y a un taux d'erreur plus important sur des images anciennes. Cela peut être partiellement palié en enlevant des classes. Neanmoins cela réste un biais inhérant à ces modèles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "986b89be",
      "metadata": {
        "id": "986b89be"
      },
      "source": [
        "# Traitement par LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xu9x0Z8Og4XJ",
      "metadata": {
        "id": "Xu9x0Z8Og4XJ"
      },
      "outputs": [],
      "source": [
        "# -- Étape 1 : Installer et importer les bibliothèques nécessaires --\n",
        "!pip install openai pillow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4sTJRskXkk",
      "metadata": {
        "id": "4d4sTJRskXkk"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n",
        "from PIL import Image, UnidentifiedImageError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o41VrrNVkbWK",
      "metadata": {
        "id": "o41VrrNVkbWK"
      },
      "outputs": [],
      "source": [
        "# --- Étape 2 : Configuration OpenRouter ---\n",
        "client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=\"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\"  # Remplace par ta clé OpenRouter\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DmSxQXcekm61",
      "metadata": {
        "id": "DmSxQXcekm61"
      },
      "outputs": [],
      "source": [
        "# --- Étape 3 : Fonctions utilitaires ---\n",
        "def encode_image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def is_image_valid(image_path):\n",
        "    try:\n",
        "        Image.open(image_path).verify()\n",
        "        return True\n",
        "    except (UnidentifiedImageError, IOError):\n",
        "        return False\n",
        "\n",
        "def query_llama_vision(image_path):\n",
        "    base64_image = encode_image_to_base64(image_path)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/llama-3.2-11b-vision-instruct:free\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Perform a descriptive indexing in English using the Library of Congress Subject Headings (LCSH) vocabulary for this archival photograph. Give your results starting with the image name followed by the indexing.\"\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def query_llama_vision_with_retry(image_path, retries=3, delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            if not is_image_valid(image_path):\n",
        "                return \"[ERROR] Unreadable or corrupted image\"\n",
        "            return query_llama_vision(image_path)\n",
        "        except Exception as e:\n",
        "            if attempt < retries - 1:\n",
        "                print(f\"⚠️ Attempt {attempt+1} failed: {e}. Retrying in {delay} sec...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                return f\"[ERROR] {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E-De9z82kuM1",
      "metadata": {
        "id": "E-De9z82kuM1"
      },
      "outputs": [],
      "source": [
        "# --- Étape 4 : Paramètres de chemin ---\n",
        "folder_path = \"/content/drive/MyDrive/Colab_Notebooks/images\"\n",
        "result_folder = \"/content/drive/MyDrive/Colab_Notebooks/images/Resultat\"\n",
        "os.makedirs(result_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p-RcjZKkk3Vm",
      "metadata": {
        "id": "p-RcjZKkk3Vm"
      },
      "outputs": [],
      "source": [
        "# --- Étape 5 : Liste des fichiers image ---\n",
        "image_filenames = sorted([\n",
        "    f for f in os.listdir(folder_path)\n",
        "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jMYyn5DQlB8g",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMYyn5DQlB8g",
        "outputId": "6f574121-4c24-4527-b516-c2572b803c53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision:   6%|▌         | 1/18 [00:04<01:18,  4.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision:  22%|██▏       | 4/18 [00:28<01:39,  7.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r🔎 Interrogation de LLaMA 3 Vision:  28%|██▊       | 5/18 [00:36<01:32,  7.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision:  67%|██████▋   | 12/18 [01:26<00:38,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision:  78%|███████▊  | 14/18 [01:37<00:24,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision:  94%|█████████▍| 17/18 [02:01<00:06,  6.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Attempt 1 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n",
            "⚠️ Attempt 2 failed: 'NoneType' object is not subscriptable. Retrying in 2 sec...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "🔎 Interrogation de LLaMA 3 Vision: 100%|██████████| 18/18 [02:09<00:00,  7.19s/it]\n"
          ]
        }
      ],
      "source": [
        "# --- Étape 6 : Génération des descriptions avec rendu ---\n",
        "results_llm = []\n",
        "for filename in tqdm(image_filenames, desc=\"🔎 Interrogation de LLaMA 3 Vision\"):\n",
        "    image_path = os.path.join(folder_path, filename)\n",
        "    llm_description = query_llama_vision_with_retry(image_path)\n",
        "    results_llm.append({\n",
        "        \"filename\": filename,\n",
        "        \"llm_description\": llm_description\n",
        "    })\n",
        "    time.sleep(2)  # Respect des limites d'OpenRouter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L_KGm10jlDs2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_KGm10jlDs2",
        "outputId": "66db86e8-c5ce-454d-c3b6-dbade5b7ca9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Résultats enregistrés dans : /content/drive/MyDrive/Colab_Notebooks/images/Resultat/résultats_llm_llama32.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Étape 7 : Sauvegarde dans un CSV ---\n",
        "csv_output_path = os.path.join(result_folder, \"résultats_llm_llama32.csv\")\n",
        "pd.DataFrame(results_llm).to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
        "print(f\"✅ Résultats enregistrés dans : {csv_output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "484c9d53",
      "metadata": {
        "id": "484c9d53"
      },
      "source": [
        "## Mise en perspectives et conclusion\n",
        "\n",
        "En conclusion, le fonctionnement du code permettant un traitment par lot, rend la méthode intéressante sur des fonds d'images en archives. De plus le rendu en CSV permet des imports, permettant d'utiliser ces classifications comme methode d'indexation automatique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d753c2c6",
      "metadata": {
        "id": "d753c2c6"
      },
      "source": [
        "## Bibliographie\n",
        "\n",
        "ARNOLD, Jonas et al., 2024. Livre blanc L’apprentissage automatique dans les archives : l’indexation en profondeur au service de l’accès aux archives. [en ligne]. Disponible à l’adresse : https://vsa-aas.ch/wp-content/uploads/2024/08/MachineLearning_im_Archiv_Whitepaper_2024-08-08_fr.pdf\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "061868647da24502b749a2c8f0117e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_143d933ad86e4a49ac8f3c7e19156610",
              "IPY_MODEL_1c724a5d2bdc4c32b5a12569f12ea10b",
              "IPY_MODEL_760c4a79c103485a83ff55592263eea4"
            ],
            "layout": "IPY_MODEL_843875d686f949b883aed003d9ed1776"
          }
        },
        "082d957918ec41fc91d3455e60d47bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143d933ad86e4a49ac8f3c7e19156610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1743e33f58a14b638885a8e0666789e8",
            "placeholder": "​",
            "style": "IPY_MODEL_c4ec3b7b366a4c7694d26bda0a1a96d7",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "149f8555ca534e249373c7f8ad8c1b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1743e33f58a14b638885a8e0666789e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18aa83fb3f60474da01d46a71c498032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d4e40588bd416a84065273203cbdbf",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a35b312001d450a8029951ef8bb37fc",
            "value": 69665
          }
        },
        "1c724a5d2bdc4c32b5a12569f12ea10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ce636d8f0740a786aceceff0f11dfb",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e52d431de7e740089fb4f9fd09cda849",
            "value": 160
          }
        },
        "2a35b312001d450a8029951ef8bb37fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "316ce7b4a3374e718526d57d3ba35d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c151624b524489a9df115165f8f14a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082d957918ec41fc91d3455e60d47bd4",
            "placeholder": "​",
            "style": "IPY_MODEL_d01eb196e9fe46c3ac78b9b441b3d654",
            "value": "model.safetensors: 100%"
          }
        },
        "4afd3b1e942544928edeb4c768d625ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c151624b524489a9df115165f8f14a4",
              "IPY_MODEL_9bf3cc31904c429a99ef0ef63daf3f2a",
              "IPY_MODEL_782500ce9b52473db6ea10458df833a0"
            ],
            "layout": "IPY_MODEL_6dfe57b9a3da444eb08cc5a3b36e1098"
          }
        },
        "504a6c6ee1724014842e4be4e90a7775": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86ffd40cdca4667ab1c8c79ea05bb8f",
            "placeholder": "​",
            "style": "IPY_MODEL_316ce7b4a3374e718526d57d3ba35d8d",
            "value": "config.json: 100%"
          }
        },
        "5122046fc5414ed4bbf1e2cc0e6776be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dfe57b9a3da444eb08cc5a3b36e1098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73f8e849c337471690e6d415bdf3bf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "760c4a79c103485a83ff55592263eea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95161adb08b4e9cb3a7a6e7bdb873a7",
            "placeholder": "​",
            "style": "IPY_MODEL_5122046fc5414ed4bbf1e2cc0e6776be",
            "value": " 160/160 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "782500ce9b52473db6ea10458df833a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cdf008d9325439199e574259b9487a5",
            "placeholder": "​",
            "style": "IPY_MODEL_d78ec22c3df04e04b337e777d8ef8da9",
            "value": " 346M/346M [00:01&lt;00:00, 296MB/s]"
          }
        },
        "7b8f3008d6e44d6ab8626ed175e5276e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c667bf5b2fb4fb6a836d7823db27293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504a6c6ee1724014842e4be4e90a7775",
              "IPY_MODEL_18aa83fb3f60474da01d46a71c498032",
              "IPY_MODEL_9b30859b93784692b2c40fbfa8f47792"
            ],
            "layout": "IPY_MODEL_149f8555ca534e249373c7f8ad8c1b3f"
          }
        },
        "80ce636d8f0740a786aceceff0f11dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "843875d686f949b883aed003d9ed1776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b30859b93784692b2c40fbfa8f47792": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e600e4083c4b4a7c8856a2ad0378168b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1270dc1e9414ce3a7a50232fe39811f",
            "value": " 69.7k/69.7k [00:00&lt;00:00, 3.49MB/s]"
          }
        },
        "9bf3cc31904c429a99ef0ef63daf3f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8f3008d6e44d6ab8626ed175e5276e",
            "max": 346293852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73f8e849c337471690e6d415bdf3bf2a",
            "value": 346293852
          }
        },
        "9cdf008d9325439199e574259b9487a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ec3b7b366a4c7694d26bda0a1a96d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d01eb196e9fe46c3ac78b9b441b3d654": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d78ec22c3df04e04b337e777d8ef8da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d95161adb08b4e9cb3a7a6e7bdb873a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1d4e40588bd416a84065273203cbdbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52d431de7e740089fb4f9fd09cda849": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e600e4083c4b4a7c8856a2ad0378168b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1270dc1e9414ce3a7a50232fe39811f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f86ffd40cdca4667ab1c8c79ea05bb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
